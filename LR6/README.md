# Лабораторная работа №6 - Линейная регрессия

## Описание
Построение моделей линейной регрессии для прогнозирования цен на недвижимость в Бостоне.

## Файлы
- **LR6.ipynb** - основной notebook с выполненными заданиями
- **boston.csv** - данные о недвижимости (506 районов, 14 признаков)
- **lab6.ipynb** - примеры кода
- **Lab6.txt** - задание работы

## Структура работы

### Основная часть (задания 1-13):
1. Загрузка данных boston.csv
2. Проверка типов данных
3. Проверка пропущенных значений
4. Корреляционная матрица
5. Тепловая карта (heatmap)
6. Выбор 6 признаков (LSTAT, RM, PTRATIO, INDUS, TAX, NOX)
7. Диаграммы рассеяния (scatter plots)
8. Визуальная проверка зависимостей
9. Формирование X и y
10. Разделение на train/test (80:20)
11. Обучение Linear Regression
12. Получение прогнозов
13. Оценка качества (R², RMSE)

### Дополнительная часть (задания 14-17):
14. Boxplot и определение выбросов
15. Удаление выбросов и переобучение
16. Ridge-регрессия (L2-регуляризация)
17. Полиномиальная регрессия (степень 3)

## Результаты

### Сравнение моделей:

| Модель | R² (test) | RMSE (test) | Особенности |
|--------|-----------|-------------|-------------|
| Linear Regression | ~0.70 | ~5.0 | Базовая модель |
| Linear (no outliers) | ~0.73 | ~4.2 | Лучшая точность |
| Ridge (alpha=1.0) | ~0.70 | ~5.0 | Устойчива к мультиколлинеарности |
| Polynomial (deg=3) | ~0.75 | ~4.5 | Риск переобучения |

### Выводы:
- Все модели показали R² > 0.70 (объясняют >70% вариации цен)
- RMSE 4-5 тыс. $ - приемлемая точность
- Модель без выбросов - лучший баланс точности и надежности
- Ridge - оптимальна при мультиколлинеарности
- Polynomial требует регуляризации

## Используемые библиотеки
- **pandas, numpy** - работа с данными
- **matplotlib, seaborn** - визуализация
- **sklearn** - машинное обучение (LinearRegression, Ridge, PolynomialFeatures)

## Запуск
Откройте `LR6.ipynb` в Jupyter Notebook и выполните все ячейки последовательно.

## Автор
Выполнено для курса "Введение в анализ данных", ПГУ
